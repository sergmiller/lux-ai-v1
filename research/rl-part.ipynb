{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import subprocess\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.dataset' from '/Users/sergmiller/Documents/my/lux-ai-v1/research/utils/dataset.py'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from utils import dataset\n",
    "\n",
    "reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(train, val, model_ff, criterion, epochs=5, batch_size=64, shuffle=True, freq=10,lr=1e-3, l2=1e-5, use_tb=True): \n",
    "    if use_tb:\n",
    "        writer = SummaryWriter()\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    ids_nn = np.arange(train.targets.shape[0])\n",
    "    \n",
    "    reshape_to_last = lambda x: torch.reshape(x, [np.prod(x.shape[:-1]), x.shape[-1]])\n",
    "\n",
    "    optimizer = optim.Adam(model_ff.parameters(), lr=lr, weight_decay=l2)\n",
    "\n",
    "    time_for_print_loss = lambda i: (i + 1) % freq == 0\n",
    "    \n",
    "    n_iter = 0\n",
    "    \n",
    "\n",
    "    for epoch in np.arange(epochs):\n",
    "        np.random.shuffle(ids_nn)\n",
    "\n",
    "        model_ff.train(True)\n",
    "\n",
    "        for b in np.arange(0, train.targets.shape[0], batch_size):\n",
    "            X_batch = torch.FloatTensor(train.features[ids_nn[b:b+batch_size]])\n",
    "            y_batch = torch.FloatTensor(train.weights[ids_nn[b:b+batch_size]])  # reward(advantage)\n",
    "            a_batch = torch.LongTensor(train.targets[ids_nn[b:b+batch_size]])  # action\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred_logits = model_ff(X_batch)\n",
    "\n",
    "            loss = criterion(y_pred_logits, y_batch, a_batch, X_batch)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if (b // batch_size + 1) % freq == 0:\n",
    "                print('train loss in %d epoch in %d batch: %.5f' %\n",
    "                  (epoch + 1, b // batch_size + 1, loss.item()))\n",
    "                \n",
    "                if use_tb:\n",
    "                    writer.add_scalar('data/train_loss', loss.item(), n_iter)\n",
    "                    writer.add_scalar('data/epoch', epoch + 1, n_iter)\n",
    "                    writer.add_scalar('data/batch', b // batch_size + 1, n_iter)\n",
    "\n",
    "                val_loss = 0\n",
    "                its = 0\n",
    "                model_ff.train(False)\n",
    "                for b in np.arange(0, val.targets.shape[0], batch_size):\n",
    "                    its += 1\n",
    "                    X_batch = torch.FloatTensor(val.features[b:b+batch_size])\n",
    "#                     X_batch = reshape_to_last(X_batch)\n",
    "\n",
    "                    y_batch = torch.FloatTensor(val.weights[b:b+batch_size])\n",
    "                    a_batch = torch.LongTensor(val.targets[b:b+batch_size])\n",
    "                    with torch.no_grad():\n",
    "                        y_pred_logits = model_ff(X_batch)\n",
    "                    loss = criterion(y_pred_logits, y_batch, a_batch, X_batch)\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= its\n",
    "                print('val loss in %d epoch: %.5f' % (epoch + 1, val_loss))\n",
    "                \n",
    "                if use_tb:\n",
    "                    writer.add_scalar('data/val_loss', val_loss, n_iter)\n",
    "                n_iter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dataset.read_datasets_from_dir(\"features_v3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'cargo_vol_total'),\n",
       " (1, 'cargo_fuel_total'),\n",
       " (2, 'unit_can_build'),\n",
       " (3, 'unit_routine'),\n",
       " (4, 'unit_last_action'),\n",
       " (5, 'near_city_dist'),\n",
       " (6, 'near_city_dir'),\n",
       " (7, 'near_city_fuel'),\n",
       " (8, 'near_city_light_upkeep'),\n",
       " (9, 'city_size'),\n",
       " (10, 'opp_near_city_dist'),\n",
       " (11, 'opp_near_city_dir'),\n",
       " (12, 'opp_near_city_fuel'),\n",
       " (13, 'opp_near_city_light_upkeep'),\n",
       " (14, 'opp_city_size'),\n",
       " (15, 'near_resource_dist'),\n",
       " (16, 'near_resource_dir'),\n",
       " (17, 'near_resource_type'),\n",
       " (18, 'near_resource_amount'),\n",
       " (19, 'my_city_count'),\n",
       " (20, 'opp_city_count'),\n",
       " (21, 'turn'),\n",
       " (22, 'is_night'),\n",
       " (23, 'time_to_night'),\n",
       " (24, 'width'),\n",
       " (25, 'height'),\n",
       " (26, 'my_research'),\n",
       " (27, 'opp_research'),\n",
       " (28, 'my_research_coal'),\n",
       " (29, 'opp_research_coal'),\n",
       " (30, 'my_research_uran'),\n",
       " (31, 'opp_research_uran'),\n",
       " (32, 'action'),\n",
       " (33, 'my_tiles'),\n",
       " (34, 'opp_tiles')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.read_columns_from_random_file(\"features_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD = dataset.concat_datasets(datasets[:-50])\n",
    "valD = dataset.concat_datasets(datasets[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['None', 'w', 'e', ..., 'p', 'p', 'p'], dtype=object)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainD.features[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 6, 11, 16, 17, 22, 28, 29, 30, 31]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.CAT_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2533363, 32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainD.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOAT_FEATURES = [i for i in range(32) if i not in dataset.CAT_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 5, 7, 8, 9, 10, 12, 13, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLOAT_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2533363, 32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainD.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../submissions/simple/models/ohe_v1\", \"rb\") as f:\n",
    "    OHE = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(t: dataset.Dataset, v: dataset.Dataset) -> (dataset.Dataset, dataset.Dataset):\n",
    "#     ohe = OneHotEncoder(sparse=False)\n",
    "    def prepare(d, is_train):\n",
    "        cf = d.features[:, dataset.CAT_FEATURES]\n",
    "        ff = d.features[:, FLOAT_FEATURES]\n",
    "        ff[ff == \"None\"] = 0\n",
    "        cf_o = OHE.fit_transform(cf) if is_train else OHE.transform(cf)\n",
    "        return dataset.Dataset(\n",
    "            features=np.array(np.concatenate([cf_o, ff], axis=1), dtype=np.float),\n",
    "            targets=np.array(d.targets, dtype=np.float),\n",
    "            weights=np.array(d.weights, dtype=np.float)\n",
    "        )\n",
    "    t = prepare(t, False)\n",
    "    v = prepare(v, False)\n",
    "    return (t,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../submissions/simple/models/ohe_v1\", \"wb\") as f:\n",
    "#     pickle.dump(ohe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 4, 5, ..., 1, 1, 1]),\n",
       " array([-2, -2, -2, ..., 0, 0, 0], dtype=object))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainD_ohe.targets, trainD_ohe.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD_ohe, valD_ohe = prepare_features(trainD, valD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2533363, 63)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainD_ohe.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNWithCustomFeatures(nn.Module):\n",
    "    def __init__(self, INPUT_F, DROP_P, H, A=6):\n",
    "        super().__init__()\n",
    "        INPUT_F_C = INPUT_F\n",
    "        self.model_ff =  nn.Sequential(\n",
    "            nn.BatchNorm1d(INPUT_F_C),\n",
    "            nn.Dropout(DROP_P),\n",
    "            nn.Linear(INPUT_F_C, H),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(DROP_P),\n",
    "            nn.Linear(H, H),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H, A)\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "#         input_x = torch.cat([x], axis=1)\n",
    "        return self.model_ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNWithCustomFeatures(63, 0.05, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTROPY_REG = 1e-5\n",
    "def policy_loss(pi_logits, reward_batch, a_batch, X_batch):\n",
    "    pi_probs = torch.nn.Softmax(dim=1)(pi_logits)\n",
    "    return torch.mean(torch.nn.CrossEntropyLoss(reduction='none')(pi_logits, a_batch) * reward_batch \n",
    "                      - torch.sum(pi_probs * torch.log(pi_probs) * ENTROPY_REG, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss in 1 epoch in 64 batch: 33.62749\n",
      "val loss in 1 epoch: 27.46838\n",
      "train loss in 1 epoch in 128 batch: 33.35194\n",
      "val loss in 1 epoch: 27.00126\n",
      "train loss in 1 epoch in 192 batch: 27.84943\n",
      "val loss in 1 epoch: 26.51209\n",
      "train loss in 1 epoch in 256 batch: 33.79417\n",
      "val loss in 1 epoch: 25.98330\n",
      "train loss in 1 epoch in 320 batch: 21.44173\n",
      "val loss in 1 epoch: 25.44491\n",
      "train loss in 1 epoch in 384 batch: 37.08883\n",
      "val loss in 1 epoch: 24.86610\n",
      "train loss in 1 epoch in 448 batch: 32.10423\n",
      "val loss in 1 epoch: 24.28592\n",
      "train loss in 1 epoch in 512 batch: 32.83151\n",
      "val loss in 1 epoch: 23.70958\n",
      "train loss in 1 epoch in 576 batch: 28.95453\n",
      "val loss in 1 epoch: 23.13052\n",
      "train loss in 1 epoch in 640 batch: 23.10432\n",
      "val loss in 1 epoch: 22.59232\n",
      "train loss in 1 epoch in 704 batch: 27.52392\n",
      "val loss in 1 epoch: 22.07282\n",
      "train loss in 1 epoch in 768 batch: 20.83056\n",
      "val loss in 1 epoch: 21.61408\n",
      "train loss in 1 epoch in 832 batch: 25.31148\n",
      "val loss in 1 epoch: 21.17967\n",
      "train loss in 1 epoch in 896 batch: 24.89939\n",
      "val loss in 1 epoch: 20.80766\n",
      "train loss in 1 epoch in 960 batch: 25.66564\n",
      "val loss in 1 epoch: 20.48738\n",
      "train loss in 1 epoch in 1024 batch: 20.48658\n",
      "val loss in 1 epoch: 20.23242\n",
      "train loss in 1 epoch in 1088 batch: 18.47395\n",
      "val loss in 1 epoch: 20.00834\n",
      "train loss in 1 epoch in 1152 batch: 19.02485\n",
      "val loss in 1 epoch: 19.83405\n",
      "train loss in 1 epoch in 1216 batch: 30.28219\n",
      "val loss in 1 epoch: 19.68906\n",
      "train loss in 1 epoch in 1280 batch: 26.30988\n",
      "val loss in 1 epoch: 19.59836\n",
      "train loss in 1 epoch in 1344 batch: 20.44616\n",
      "val loss in 1 epoch: 19.50448\n",
      "train loss in 1 epoch in 1408 batch: 40.45268\n",
      "val loss in 1 epoch: 19.44875\n",
      "train loss in 1 epoch in 1472 batch: 27.02892\n",
      "val loss in 1 epoch: 19.39123\n",
      "train loss in 1 epoch in 1536 batch: 26.70045\n",
      "val loss in 1 epoch: 19.36120\n",
      "train loss in 1 epoch in 1600 batch: 33.82317\n",
      "val loss in 1 epoch: 19.33638\n",
      "train loss in 1 epoch in 1664 batch: 24.55053\n",
      "val loss in 1 epoch: 19.31594\n",
      "train loss in 1 epoch in 1728 batch: 20.58430\n",
      "val loss in 1 epoch: 19.29892\n",
      "train loss in 1 epoch in 1792 batch: 27.23018\n",
      "val loss in 1 epoch: 19.28769\n",
      "train loss in 1 epoch in 1856 batch: 23.67039\n",
      "val loss in 1 epoch: 19.28003\n",
      "train loss in 1 epoch in 1920 batch: 31.92381\n",
      "val loss in 1 epoch: 19.27370\n",
      "train loss in 1 epoch in 1984 batch: 21.85939\n",
      "val loss in 1 epoch: 19.26569\n",
      "train loss in 1 epoch in 2048 batch: 14.98724\n",
      "val loss in 1 epoch: 19.25637\n",
      "train loss in 1 epoch in 2112 batch: 14.96092\n",
      "val loss in 1 epoch: 19.24983\n",
      "train loss in 1 epoch in 2176 batch: 29.01925\n",
      "val loss in 1 epoch: 19.24856\n",
      "train loss in 1 epoch in 2240 batch: 19.54274\n",
      "val loss in 1 epoch: 19.23540\n",
      "train loss in 1 epoch in 2304 batch: 18.12540\n",
      "val loss in 1 epoch: 19.23292\n",
      "train loss in 1 epoch in 2368 batch: 20.21809\n",
      "val loss in 1 epoch: 19.22947\n",
      "train loss in 1 epoch in 2432 batch: 22.81871\n",
      "val loss in 1 epoch: 19.21857\n",
      "train loss in 1 epoch in 2496 batch: 14.44142\n",
      "val loss in 1 epoch: 19.20770\n",
      "train loss in 1 epoch in 2560 batch: 13.56404\n",
      "val loss in 1 epoch: 19.20388\n",
      "train loss in 1 epoch in 2624 batch: 21.50717\n",
      "val loss in 1 epoch: 19.20423\n",
      "train loss in 1 epoch in 2688 batch: 22.23608\n",
      "val loss in 1 epoch: 19.20507\n",
      "train loss in 1 epoch in 2752 batch: 25.53156\n",
      "val loss in 1 epoch: 19.21449\n",
      "train loss in 1 epoch in 2816 batch: 16.36428\n",
      "val loss in 1 epoch: 19.20493\n",
      "train loss in 1 epoch in 2880 batch: 18.85041\n",
      "val loss in 1 epoch: 19.18961\n",
      "train loss in 1 epoch in 2944 batch: 18.82244\n",
      "val loss in 1 epoch: 19.17986\n",
      "train loss in 1 epoch in 3008 batch: 25.28986\n",
      "val loss in 1 epoch: 19.17750\n",
      "train loss in 1 epoch in 3072 batch: 21.44834\n",
      "val loss in 1 epoch: 19.17877\n",
      "train loss in 1 epoch in 3136 batch: 22.33917\n",
      "val loss in 1 epoch: 19.17648\n",
      "train loss in 1 epoch in 3200 batch: 22.06647\n",
      "val loss in 1 epoch: 19.18263\n",
      "train loss in 1 epoch in 3264 batch: 18.27385\n",
      "val loss in 1 epoch: 19.18757\n",
      "train loss in 1 epoch in 3328 batch: 31.10750\n",
      "val loss in 1 epoch: 19.18096\n",
      "train loss in 1 epoch in 3392 batch: 20.47194\n",
      "val loss in 1 epoch: 19.17547\n",
      "train loss in 1 epoch in 3456 batch: 13.64805\n",
      "val loss in 1 epoch: 19.17691\n",
      "train loss in 1 epoch in 3520 batch: 18.32968\n",
      "val loss in 1 epoch: 19.16495\n",
      "train loss in 1 epoch in 3584 batch: 15.58597\n",
      "val loss in 1 epoch: 19.16763\n",
      "train loss in 1 epoch in 3648 batch: 14.08232\n",
      "val loss in 1 epoch: 19.16373\n",
      "train loss in 1 epoch in 3712 batch: 15.24659\n",
      "val loss in 1 epoch: 19.16646\n",
      "train loss in 1 epoch in 3776 batch: 33.33365\n",
      "val loss in 1 epoch: 19.16042\n",
      "train loss in 1 epoch in 3840 batch: 19.87501\n",
      "val loss in 1 epoch: 19.15847\n",
      "train loss in 1 epoch in 3904 batch: 19.09948\n",
      "val loss in 1 epoch: 19.14413\n",
      "train loss in 1 epoch in 3968 batch: 14.17772\n",
      "val loss in 1 epoch: 19.15061\n",
      "train loss in 1 epoch in 4032 batch: 19.20924\n",
      "val loss in 1 epoch: 19.14084\n",
      "train loss in 1 epoch in 4096 batch: 20.08698\n",
      "val loss in 1 epoch: 19.14509\n",
      "train loss in 1 epoch in 4160 batch: 12.43129\n",
      "val loss in 1 epoch: 19.14212\n",
      "train loss in 1 epoch in 4224 batch: 16.90128\n",
      "val loss in 1 epoch: 19.13711\n",
      "train loss in 1 epoch in 4288 batch: 14.60515\n",
      "val loss in 1 epoch: 19.14373\n",
      "train loss in 1 epoch in 4352 batch: 18.52273\n",
      "val loss in 1 epoch: 19.14205\n",
      "train loss in 1 epoch in 4416 batch: 25.77982\n",
      "val loss in 1 epoch: 19.14527\n",
      "train loss in 1 epoch in 4480 batch: 22.90985\n",
      "val loss in 1 epoch: 19.14462\n",
      "train loss in 1 epoch in 4544 batch: 19.78962\n",
      "val loss in 1 epoch: 19.13670\n",
      "train loss in 1 epoch in 4608 batch: 19.76224\n",
      "val loss in 1 epoch: 19.14018\n",
      "train loss in 1 epoch in 4672 batch: 18.28133\n",
      "val loss in 1 epoch: 19.14161\n",
      "train loss in 1 epoch in 4736 batch: 13.68883\n",
      "val loss in 1 epoch: 19.13819\n",
      "train loss in 1 epoch in 4800 batch: 18.09784\n",
      "val loss in 1 epoch: 19.14568\n",
      "train loss in 1 epoch in 4864 batch: 25.31864\n",
      "val loss in 1 epoch: 19.13873\n",
      "train loss in 1 epoch in 4928 batch: 18.58765\n",
      "val loss in 1 epoch: 19.14204\n",
      "train loss in 1 epoch in 4992 batch: 22.71815\n",
      "val loss in 1 epoch: 19.14408\n",
      "train loss in 1 epoch in 5056 batch: 15.91109\n",
      "val loss in 1 epoch: 19.14662\n",
      "train loss in 1 epoch in 5120 batch: 26.86213\n",
      "val loss in 1 epoch: 19.14419\n",
      "train loss in 1 epoch in 5184 batch: 20.74017\n",
      "val loss in 1 epoch: 19.14852\n",
      "train loss in 1 epoch in 5248 batch: 20.62681\n",
      "val loss in 1 epoch: 19.15188\n",
      "train loss in 1 epoch in 5312 batch: 26.78531\n",
      "val loss in 1 epoch: 19.14052\n",
      "train loss in 1 epoch in 5376 batch: 24.13913\n",
      "val loss in 1 epoch: 19.13727\n",
      "train loss in 1 epoch in 5440 batch: 21.46977\n",
      "val loss in 1 epoch: 19.14244\n",
      "train loss in 1 epoch in 5504 batch: 23.71302\n",
      "val loss in 1 epoch: 19.14752\n",
      "train loss in 1 epoch in 5568 batch: 24.46798\n",
      "val loss in 1 epoch: 19.15357\n",
      "train loss in 1 epoch in 5632 batch: 18.76479\n",
      "val loss in 1 epoch: 19.16037\n",
      "train loss in 1 epoch in 5696 batch: 14.03557\n",
      "val loss in 1 epoch: 19.15475\n",
      "train loss in 1 epoch in 5760 batch: 22.66597\n",
      "val loss in 1 epoch: 19.16038\n",
      "train loss in 1 epoch in 5824 batch: 18.25641\n",
      "val loss in 1 epoch: 19.15661\n",
      "train loss in 1 epoch in 5888 batch: 25.77304\n",
      "val loss in 1 epoch: 19.15162\n",
      "train loss in 1 epoch in 5952 batch: 26.01000\n",
      "val loss in 1 epoch: 19.14570\n",
      "train loss in 1 epoch in 6016 batch: 17.52146\n",
      "val loss in 1 epoch: 19.14795\n",
      "train loss in 1 epoch in 6080 batch: 11.35325\n",
      "val loss in 1 epoch: 19.14120\n",
      "train loss in 1 epoch in 6144 batch: 29.35543\n",
      "val loss in 1 epoch: 19.13745\n",
      "train loss in 1 epoch in 6208 batch: 28.54717\n",
      "val loss in 1 epoch: 19.13754\n",
      "train loss in 1 epoch in 6272 batch: 17.90462\n"
     ]
    }
   ],
   "source": [
    "learn(trainD_ohe, valD_ohe, model, policy_loss, lr=1e-4, batch_size=32, epochs=5, freq=64, l2=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8303,  0.1936,  0.8113],\n",
       "        [ 0.8070, -0.6903, -0.6328]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.6177, 0.9913])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss(reduction='none')(torch.randn(2, 3), torch.LongTensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../submissions/simple/models/policy_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.7694, -46.3936,  -7.7365,  -9.8257,   0.2452,  59.4586]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.Tensor(trainD_ohe.features[0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.forward(torch.Tensor(trainD_ohe.features[0]).reshape(1, -1)).cpu().detach().numpy().reshape(-1)\n",
    "p = np.clip(p, -30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.10283675e-11, 8.75651089e-27, 4.08547019e-17, 5.05711219e-18,\n",
       "       1.19576061e-13, 1.00000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(p) / np.sum(np.exp(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([False, True], dtype=object),\n",
       " array([1, 2, 3], dtype=object),\n",
       " array(['None', 'bcity', 'e', 'n', 'p', 's', 'w'], dtype=object),\n",
       " array(['None', 'c', 'e', 'n', 's', 'w'], dtype=object),\n",
       " array(['None', 'e', 'n', 's', 'w'], dtype=object),\n",
       " array(['None', 'c', 'e', 'n', 's', 'w'], dtype=object),\n",
       " array(['None', 'coal', 'uranium', 'wood'], dtype=object),\n",
       " array([False, True], dtype=object),\n",
       " array([False, True], dtype=object),\n",
       " array([False, True], dtype=object),\n",
       " array([False, True], dtype=object),\n",
       " array([False, True], dtype=object)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, False, 2, 'None', 0, 'c', 0.0, 23.0, 1, 1, 'n', 0.0, 23.0, 1,\n",
       "       1, 'w', 'wood', 800, 1, 1, 0, False, 30, 16, 16, 0, 0, False,\n",
       "       False, False, False], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainD.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f80458fbfd0>]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainD.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_bot = \"../submissions/simple/main.py\"\n",
    "replays = \"replays\"\n",
    "\n",
    "def run_game(left_bot=simple_bot, right_bot=simple_bot, seed=42, loglevel=2):\n",
    "    replay_path = \"replay.json\"\n",
    "    python_v = \"python3.7\"\n",
    "    \n",
    "    replay_path = os.path.join(replays, str(np.random.randint(1e9)) + \".json\")\n",
    "    \n",
    "    size = np.random.choice([12,16,24,32], size=1)[0]\n",
    "    \n",
    "    res = subprocess.run([\n",
    "        \"lux-ai-2021\",\n",
    "        left_bot,\n",
    "        right_bot,\n",
    "#         \"--statefulReplay\",\n",
    "        \"--width={}\".format(size),\n",
    "        \"--height={}\".format(size),\n",
    "        \"--loglevel={}\".format(loglevel),\n",
    "        \"--python={}\".format(python_v),\n",
    "        \"--seed={}\".format(seed),\n",
    "        \"--out={}\".format(replay_path)], stdout=subprocess.PIPE)\n",
    "    \n",
    "    if loglevel > 0:\n",
    "        print(res.stdout.decode())\n",
    "\n",
    "    assert res.returncode == 0\n",
    "\n",
    "    with open(replay_path, \"r\") as f:\n",
    "        result = json.load(f)\n",
    "    return result, res.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def build_runnable_bot_with_flags(flags: dict, origin = simple_bot, base_path = '../submissions/simple/') -> str:\n",
    "    lines = []\n",
    "    with open(origin, \"r\") as f:\n",
    "        for line in f:\n",
    "            lines.append(line[:-1])\n",
    "    text = '\\n'.join(lines)\n",
    "    f = json.dumps(flags)\n",
    "    text = text.format(f)\n",
    "    h = int(hashlib.sha256(f.encode('utf-8')).hexdigest(), 16) % (10 ** 18)\n",
    "    path = base_path + \"main_\" + str(h) + \".py\"\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(text)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_series(results: list):\n",
    "    wins = []\n",
    "    for i, r in enumerate(results):\n",
    "        ranks = r[0]['results']['ranks']\n",
    "        teams = r[0]['teamDetails']\n",
    "        if ranks[0]['rank'] == 1 and ranks[1]['rank'] == 2:\n",
    "            if ranks[0][\"agentID\"] == i % 2:\n",
    "                wins.append(1)\n",
    "            else:\n",
    "                wins.append(0)\n",
    "        else:\n",
    "            wins.append(0.5)\n",
    "    return wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(d, p=0.5):\n",
    "    N = len(d.features)\n",
    "    ids = np.random.choice(N, size=int(N * p))\n",
    "    return dataset.Dataset(features = d.features[ids], weights = d.weights[ids], targets = d.targets[ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1, winrate: 0.0, max_step: 110, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/907588952.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.78826\n",
      "val loss in 1 epoch: -0.84482\n",
      "train loss in 1 epoch in 2 batch: -0.80270\n",
      "val loss in 1 epoch: -0.84499\n",
      "train loss in 1 epoch in 3 batch: -0.89367\n",
      "val loss in 1 epoch: -0.84518\n",
      "Round 2, winrate: 0.0, max_step: 237, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/934876622.json'}\n",
      "train loss in 1 epoch in 1 batch: 5.13725\n",
      "val loss in 1 epoch: 4.61682\n",
      "train loss in 1 epoch in 2 batch: 5.55042\n",
      "val loss in 1 epoch: 4.61601\n",
      "train loss in 1 epoch in 3 batch: 5.02045\n",
      "val loss in 1 epoch: 4.61514\n",
      "train loss in 1 epoch in 4 batch: 5.37316\n",
      "val loss in 1 epoch: 4.61426\n",
      "train loss in 1 epoch in 5 batch: 5.22674\n",
      "val loss in 1 epoch: 4.61335\n",
      "train loss in 1 epoch in 6 batch: 5.83689\n",
      "val loss in 1 epoch: 4.61244\n",
      "train loss in 1 epoch in 7 batch: 4.49776\n",
      "val loss in 1 epoch: 4.61151\n",
      "train loss in 1 epoch in 8 batch: 2.64605\n",
      "val loss in 1 epoch: 4.61069\n",
      "Round 3, winrate: 0.0, max_step: 189, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/173402956.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.74813\n",
      "val loss in 1 epoch: -0.42166\n",
      "train loss in 1 epoch in 2 batch: -0.31536\n",
      "val loss in 1 epoch: -0.42168\n",
      "train loss in 1 epoch in 3 batch: -0.44151\n",
      "val loss in 1 epoch: -0.42171\n",
      "train loss in 1 epoch in 4 batch: -0.54702\n",
      "val loss in 1 epoch: -0.42174\n",
      "train loss in 1 epoch in 5 batch: -0.43324\n",
      "val loss in 1 epoch: -0.42176\n",
      "Round 4, winrate: 0.0, max_step: 271, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/283300719.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.48047\n",
      "val loss in 1 epoch: -1.19026\n",
      "train loss in 1 epoch in 2 batch: -1.47552\n",
      "val loss in 1 epoch: -1.19032\n",
      "train loss in 1 epoch in 3 batch: -1.66459\n",
      "val loss in 1 epoch: -1.19037\n",
      "train loss in 1 epoch in 4 batch: -1.88916\n",
      "val loss in 1 epoch: -1.19043\n",
      "train loss in 1 epoch in 5 batch: -1.40204\n",
      "val loss in 1 epoch: -1.19048\n",
      "train loss in 1 epoch in 6 batch: -1.37513\n",
      "val loss in 1 epoch: -1.19054\n",
      "train loss in 1 epoch in 7 batch: -0.62759\n",
      "val loss in 1 epoch: -1.19059\n",
      "train loss in 1 epoch in 8 batch: -2.46040\n",
      "val loss in 1 epoch: -1.19064\n",
      "train loss in 1 epoch in 9 batch: -0.54020\n",
      "val loss in 1 epoch: -1.19069\n",
      "train loss in 1 epoch in 10 batch: -1.04689\n",
      "val loss in 1 epoch: -1.19074\n",
      "train loss in 1 epoch in 11 batch: -1.61991\n",
      "val loss in 1 epoch: -1.19079\n",
      "Round 5, winrate: 0.0, max_step: 230, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/52796734.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.21628\n",
      "val loss in 1 epoch: -0.41802\n",
      "train loss in 1 epoch in 2 batch: -0.60028\n",
      "val loss in 1 epoch: -0.41803\n",
      "train loss in 1 epoch in 3 batch: -0.40688\n",
      "val loss in 1 epoch: -0.41805\n",
      "train loss in 1 epoch in 4 batch: -0.39820\n",
      "val loss in 1 epoch: -0.41806\n",
      "train loss in 1 epoch in 5 batch: -0.46507\n",
      "val loss in 1 epoch: -0.41807\n",
      "Round 6, winrate: 0.0, max_step: 190, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/153411311.json'}\n",
      "train loss in 1 epoch in 1 batch: -1.94941\n",
      "val loss in 1 epoch: -1.93575\n",
      "train loss in 1 epoch in 2 batch: -2.11855\n",
      "val loss in 1 epoch: -1.93578\n",
      "train loss in 1 epoch in 3 batch: -1.86115\n",
      "val loss in 1 epoch: -1.93581\n",
      "train loss in 1 epoch in 4 batch: -2.06916\n",
      "val loss in 1 epoch: -1.93584\n",
      "train loss in 1 epoch in 5 batch: -1.99165\n",
      "val loss in 1 epoch: -1.93587\n",
      "Round 7, winrate: 0.0, max_step: 230, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/13210932.json'}\n",
      "train loss in 1 epoch in 1 batch: -1.05314\n",
      "val loss in 1 epoch: -1.30922\n",
      "train loss in 1 epoch in 2 batch: -0.69430\n",
      "val loss in 1 epoch: -1.30924\n",
      "train loss in 1 epoch in 3 batch: -1.82678\n",
      "val loss in 1 epoch: -1.30927\n",
      "train loss in 1 epoch in 4 batch: -1.39762\n",
      "val loss in 1 epoch: -1.30929\n",
      "train loss in 1 epoch in 5 batch: -1.56152\n",
      "val loss in 1 epoch: -1.30931\n",
      "train loss in 1 epoch in 6 batch: -1.40277\n",
      "val loss in 1 epoch: -1.30933\n",
      "Round 8, winrate: 0.0, max_step: 359, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/758925067.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.60559\n",
      "val loss in 1 epoch: 0.59824\n",
      "train loss in 1 epoch in 2 batch: 0.47922\n",
      "val loss in 1 epoch: 0.59823\n",
      "train loss in 1 epoch in 3 batch: 0.64481\n",
      "val loss in 1 epoch: 0.59822\n",
      "train loss in 1 epoch in 4 batch: 0.62774\n",
      "val loss in 1 epoch: 0.59821\n",
      "train loss in 1 epoch in 5 batch: 0.70852\n",
      "val loss in 1 epoch: 0.59820\n",
      "train loss in 1 epoch in 6 batch: 0.43259\n",
      "val loss in 1 epoch: 0.59819\n",
      "train loss in 1 epoch in 7 batch: 0.77826\n",
      "val loss in 1 epoch: 0.59818\n",
      "train loss in 1 epoch in 8 batch: 0.29469\n",
      "val loss in 1 epoch: 0.59817\n",
      "train loss in 1 epoch in 9 batch: 0.60061\n",
      "val loss in 1 epoch: 0.59816\n",
      "train loss in 1 epoch in 10 batch: 0.97690\n",
      "val loss in 1 epoch: 0.59815\n",
      "train loss in 1 epoch in 11 batch: 0.53848\n",
      "val loss in 1 epoch: 0.59814\n",
      "train loss in 1 epoch in 12 batch: 0.86818\n",
      "val loss in 1 epoch: 0.59813\n",
      "train loss in 1 epoch in 13 batch: 0.48657\n",
      "val loss in 1 epoch: 0.59812\n",
      "Round 9, winrate: 0.0, max_step: 229, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/259974304.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.58486\n",
      "val loss in 1 epoch: -0.50747\n",
      "train loss in 1 epoch in 2 batch: -0.39638\n",
      "val loss in 1 epoch: -0.50748\n",
      "train loss in 1 epoch in 3 batch: -0.66122\n",
      "val loss in 1 epoch: -0.50750\n",
      "train loss in 1 epoch in 4 batch: -0.59511\n",
      "val loss in 1 epoch: -0.50751\n",
      "train loss in 1 epoch in 5 batch: -0.44128\n",
      "val loss in 1 epoch: -0.50753\n",
      "Round 10, winrate: 0.0, max_step: 194, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/255510571.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.09575\n",
      "val loss in 1 epoch: -0.06826\n",
      "train loss in 1 epoch in 2 batch: -0.16778\n",
      "val loss in 1 epoch: -0.06826\n",
      "train loss in 1 epoch in 3 batch: -0.06255\n",
      "val loss in 1 epoch: -0.06826\n",
      "train loss in 1 epoch in 4 batch: 0.05086\n",
      "val loss in 1 epoch: -0.06827\n",
      "Round 11, winrate: 0.0, max_step: 191, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/300742822.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.66832\n",
      "val loss in 1 epoch: 0.34809\n",
      "train loss in 1 epoch in 2 batch: 0.29853\n",
      "val loss in 1 epoch: 0.34808\n",
      "train loss in 1 epoch in 3 batch: 0.16139\n",
      "val loss in 1 epoch: 0.34807\n",
      "train loss in 1 epoch in 4 batch: 0.45237\n",
      "val loss in 1 epoch: 0.34807\n",
      "train loss in 1 epoch in 5 batch: 0.46495\n",
      "val loss in 1 epoch: 0.34806\n",
      "train loss in 1 epoch in 6 batch: 0.32393\n",
      "val loss in 1 epoch: 0.34805\n",
      "train loss in 1 epoch in 7 batch: 0.21322\n",
      "val loss in 1 epoch: 0.34805\n",
      "Round 12, winrate: 0.0, max_step: 149, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/224030150.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.87672\n",
      "val loss in 1 epoch: -0.84610\n",
      "train loss in 1 epoch in 2 batch: -0.89217\n",
      "val loss in 1 epoch: -0.84611\n",
      "train loss in 1 epoch in 3 batch: -0.72494\n",
      "val loss in 1 epoch: -0.84611\n",
      "train loss in 1 epoch in 4 batch: -1.01009\n",
      "val loss in 1 epoch: -0.84612\n",
      "train loss in 1 epoch in 5 batch: -0.81346\n",
      "val loss in 1 epoch: -0.84613\n",
      "Round 13, winrate: 0.0, max_step: 158, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/135191679.json'}\n",
      "train loss in 1 epoch in 1 batch: -2.35160\n",
      "val loss in 1 epoch: -2.25682\n",
      "train loss in 1 epoch in 2 batch: -2.23104\n",
      "val loss in 1 epoch: -2.25685\n",
      "train loss in 1 epoch in 3 batch: -2.19501\n",
      "val loss in 1 epoch: -2.25688\n",
      "train loss in 1 epoch in 4 batch: -2.29996\n",
      "val loss in 1 epoch: -2.25690\n",
      "train loss in 1 epoch in 5 batch: -2.06601\n",
      "val loss in 1 epoch: -2.25693\n",
      "train loss in 1 epoch in 6 batch: -2.40548\n",
      "val loss in 1 epoch: -2.25696\n",
      "train loss in 1 epoch in 7 batch: -2.56412\n",
      "val loss in 1 epoch: -2.25699\n",
      "Round 14, winrate: 0.0, max_step: 277, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/931492602.json'}\n",
      "train loss in 1 epoch in 1 batch: 5.04925\n",
      "val loss in 1 epoch: 4.70940\n",
      "train loss in 1 epoch in 2 batch: 4.63185\n",
      "val loss in 1 epoch: 4.70931\n",
      "train loss in 1 epoch in 3 batch: 4.64196\n",
      "val loss in 1 epoch: 4.70922\n",
      "train loss in 1 epoch in 4 batch: 4.85492\n",
      "val loss in 1 epoch: 4.70912\n",
      "train loss in 1 epoch in 5 batch: 4.75798\n",
      "val loss in 1 epoch: 4.70902\n",
      "train loss in 1 epoch in 6 batch: 5.44312\n",
      "val loss in 1 epoch: 4.70893\n",
      "train loss in 1 epoch in 7 batch: 5.92989\n",
      "val loss in 1 epoch: 4.70883\n",
      "train loss in 1 epoch in 8 batch: 4.58493\n",
      "val loss in 1 epoch: 4.70873\n",
      "train loss in 1 epoch in 9 batch: 5.33622\n",
      "val loss in 1 epoch: 4.70863\n",
      "train loss in 1 epoch in 10 batch: 5.26065\n",
      "val loss in 1 epoch: 4.70854\n",
      "train loss in 1 epoch in 11 batch: 5.04934\n",
      "val loss in 1 epoch: 4.70844\n",
      "train loss in 1 epoch in 12 batch: 5.52899\n",
      "val loss in 1 epoch: 4.70834\n",
      "train loss in 1 epoch in 13 batch: 2.88098\n",
      "val loss in 1 epoch: 4.70825\n",
      "Round 15, winrate: 0.0, max_step: 159, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/966330317.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.46870\n",
      "val loss in 1 epoch: -0.11618\n",
      "train loss in 1 epoch in 2 batch: -0.24425\n",
      "val loss in 1 epoch: -0.11619\n",
      "train loss in 1 epoch in 3 batch: 0.06934\n",
      "val loss in 1 epoch: -0.11619\n",
      "train loss in 1 epoch in 4 batch: 0.21445\n",
      "val loss in 1 epoch: -0.11620\n",
      "train loss in 1 epoch in 5 batch: -0.17789\n",
      "val loss in 1 epoch: -0.11621\n",
      "train loss in 1 epoch in 6 batch: 0.06620\n",
      "val loss in 1 epoch: -0.11622\n",
      "train loss in 1 epoch in 7 batch: 0.01077\n",
      "val loss in 1 epoch: -0.11622\n",
      "Round 16, winrate: 0.25, max_step: 238, example: {'ranks': [{'rank': 1, 'agentID': 0}, {'rank': 2, 'agentID': 1}], 'replayFile': 'replays/476274519.json'}\n",
      "train loss in 1 epoch in 1 batch: 1.01493\n",
      "val loss in 1 epoch: 0.95166\n",
      "train loss in 1 epoch in 2 batch: 1.01432\n",
      "val loss in 1 epoch: 0.95165\n",
      "train loss in 1 epoch in 3 batch: 0.94507\n",
      "val loss in 1 epoch: 0.95164\n",
      "train loss in 1 epoch in 4 batch: 1.02749\n",
      "val loss in 1 epoch: 0.95163\n",
      "train loss in 1 epoch in 5 batch: 1.08482\n",
      "val loss in 1 epoch: 0.95161\n",
      "train loss in 1 epoch in 6 batch: 1.12388\n",
      "val loss in 1 epoch: 0.95160\n",
      "train loss in 1 epoch in 7 batch: 1.15320\n",
      "val loss in 1 epoch: 0.95159\n",
      "train loss in 1 epoch in 8 batch: 0.84167\n",
      "val loss in 1 epoch: 0.95158\n",
      "train loss in 1 epoch in 9 batch: 1.31168\n",
      "val loss in 1 epoch: 0.95157\n",
      "Round 17, winrate: 0.0, max_step: 109, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/877612262.json'}\n",
      "train loss in 1 epoch in 1 batch: -1.69527\n",
      "val loss in 1 epoch: -1.42074\n",
      "train loss in 1 epoch in 2 batch: -1.64499\n",
      "val loss in 1 epoch: -1.42076\n",
      "train loss in 1 epoch in 3 batch: -1.64885\n",
      "val loss in 1 epoch: -1.42077\n",
      "Round 18, winrate: 0.0, max_step: 190, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/933694474.json'}\n",
      "train loss in 1 epoch in 1 batch: -1.31211\n",
      "val loss in 1 epoch: -1.28140\n",
      "train loss in 1 epoch in 2 batch: -1.61957\n",
      "val loss in 1 epoch: -1.28142\n",
      "train loss in 1 epoch in 3 batch: -1.25963\n",
      "val loss in 1 epoch: -1.28144\n",
      "train loss in 1 epoch in 4 batch: -1.72784\n",
      "val loss in 1 epoch: -1.28146\n",
      "train loss in 1 epoch in 5 batch: -1.57024\n",
      "val loss in 1 epoch: -1.28148\n",
      "Round 19, winrate: 0.25, max_step: 270, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/726849742.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.53172\n",
      "val loss in 1 epoch: -0.55671\n",
      "train loss in 1 epoch in 2 batch: -0.16063\n",
      "val loss in 1 epoch: -0.55673\n",
      "train loss in 1 epoch in 3 batch: -1.09229\n",
      "val loss in 1 epoch: -0.55674\n",
      "train loss in 1 epoch in 4 batch: -0.40781\n",
      "val loss in 1 epoch: -0.55676\n",
      "train loss in 1 epoch in 5 batch: -1.07865\n",
      "val loss in 1 epoch: -0.55678\n",
      "train loss in 1 epoch in 6 batch: -0.38553\n",
      "val loss in 1 epoch: -0.55680\n",
      "train loss in 1 epoch in 7 batch: -0.62113\n",
      "val loss in 1 epoch: -0.55682\n",
      "Round 20, winrate: 0.0, max_step: 359, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/931492602.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.63110\n",
      "val loss in 1 epoch: 0.48638\n",
      "train loss in 1 epoch in 2 batch: 0.65260\n",
      "val loss in 1 epoch: 0.48637\n",
      "train loss in 1 epoch in 3 batch: 0.50362\n",
      "val loss in 1 epoch: 0.48636\n",
      "train loss in 1 epoch in 4 batch: 0.58035\n",
      "val loss in 1 epoch: 0.48635\n",
      "train loss in 1 epoch in 5 batch: 0.39935\n",
      "val loss in 1 epoch: 0.48634\n",
      "train loss in 1 epoch in 6 batch: 0.39442\n",
      "val loss in 1 epoch: 0.48634\n",
      "train loss in 1 epoch in 7 batch: 0.61267\n",
      "val loss in 1 epoch: 0.48633\n",
      "train loss in 1 epoch in 8 batch: 0.26971\n",
      "val loss in 1 epoch: 0.48632\n",
      "Round 21, winrate: 0.0, max_step: 235, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/613923774.json'}\n",
      "train loss in 1 epoch in 1 batch: -2.59769\n",
      "val loss in 1 epoch: -2.68736\n",
      "train loss in 1 epoch in 2 batch: -2.72344\n",
      "val loss in 1 epoch: -2.68740\n",
      "train loss in 1 epoch in 3 batch: -2.53022\n",
      "val loss in 1 epoch: -2.68743\n",
      "train loss in 1 epoch in 4 batch: -2.67212\n",
      "val loss in 1 epoch: -2.68747\n",
      "train loss in 1 epoch in 5 batch: -2.59950\n",
      "val loss in 1 epoch: -2.68751\n",
      "train loss in 1 epoch in 6 batch: -2.63336\n",
      "val loss in 1 epoch: -2.68755\n",
      "train loss in 1 epoch in 7 batch: -2.96123\n",
      "val loss in 1 epoch: -2.68758\n",
      "train loss in 1 epoch in 8 batch: -3.11111\n",
      "val loss in 1 epoch: -2.68762\n",
      "train loss in 1 epoch in 9 batch: -2.73565\n",
      "val loss in 1 epoch: -2.68766\n",
      "train loss in 1 epoch in 10 batch: -2.84212\n",
      "val loss in 1 epoch: -2.68770\n",
      "train loss in 1 epoch in 11 batch: -2.41540\n",
      "val loss in 1 epoch: -2.68774\n",
      "Round 22, winrate: 0.0, max_step: 194, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/358365762.json'}\n",
      "train loss in 1 epoch in 1 batch: -2.59547\n",
      "val loss in 1 epoch: -2.17087\n",
      "train loss in 1 epoch in 2 batch: -2.99333\n",
      "val loss in 1 epoch: -2.17090\n",
      "train loss in 1 epoch in 3 batch: -1.89471\n",
      "val loss in 1 epoch: -2.17094\n",
      "train loss in 1 epoch in 4 batch: -2.39235\n",
      "val loss in 1 epoch: -2.17097\n",
      "train loss in 1 epoch in 5 batch: -2.36492\n",
      "val loss in 1 epoch: -2.17100\n",
      "train loss in 1 epoch in 6 batch: -1.62607\n",
      "val loss in 1 epoch: -2.17103\n",
      "Round 23, winrate: 0.0, max_step: 149, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/650599866.json'}\n",
      "train loss in 1 epoch in 1 batch: -2.10235\n",
      "val loss in 1 epoch: -2.20132\n",
      "train loss in 1 epoch in 2 batch: -2.41695\n",
      "val loss in 1 epoch: -2.20135\n",
      "train loss in 1 epoch in 3 batch: -2.26216\n",
      "val loss in 1 epoch: -2.20138\n",
      "train loss in 1 epoch in 4 batch: -2.78631\n",
      "val loss in 1 epoch: -2.20142\n",
      "Round 24, winrate: 0.0, max_step: 309, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/209080051.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.05336\n",
      "val loss in 1 epoch: 0.29443\n",
      "train loss in 1 epoch in 2 batch: 0.70072\n",
      "val loss in 1 epoch: 0.29441\n",
      "train loss in 1 epoch in 3 batch: -0.13749\n",
      "val loss in 1 epoch: 0.29439\n",
      "train loss in 1 epoch in 4 batch: 0.23117\n",
      "val loss in 1 epoch: 0.29437\n",
      "train loss in 1 epoch in 5 batch: 0.24472\n",
      "val loss in 1 epoch: 0.29434\n",
      "train loss in 1 epoch in 6 batch: 0.54205\n",
      "val loss in 1 epoch: 0.29432\n",
      "train loss in 1 epoch in 7 batch: 0.37980\n",
      "val loss in 1 epoch: 0.29430\n",
      "train loss in 1 epoch in 8 batch: 0.32117\n",
      "val loss in 1 epoch: 0.29428\n",
      "train loss in 1 epoch in 9 batch: 0.47770\n",
      "val loss in 1 epoch: 0.29426\n",
      "train loss in 1 epoch in 10 batch: 0.28264\n",
      "val loss in 1 epoch: 0.29424\n",
      "Round 25, winrate: 0.0, max_step: 196, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/131790176.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.24180\n",
      "val loss in 1 epoch: -0.17626\n",
      "train loss in 1 epoch in 2 batch: -0.31223\n",
      "val loss in 1 epoch: -0.17627\n",
      "train loss in 1 epoch in 3 batch: -0.21552\n",
      "val loss in 1 epoch: -0.17628\n",
      "train loss in 1 epoch in 4 batch: 0.02924\n",
      "val loss in 1 epoch: -0.17628\n",
      "train loss in 1 epoch in 5 batch: -0.04302\n",
      "val loss in 1 epoch: -0.17629\n",
      "train loss in 1 epoch in 6 batch: -0.28888\n",
      "val loss in 1 epoch: -0.17630\n",
      "Round 26, winrate: 0.0, max_step: 351, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/758925067.json'}\n",
      "train loss in 1 epoch in 1 batch: 4.48167\n",
      "val loss in 1 epoch: 4.77277\n",
      "train loss in 1 epoch in 2 batch: 4.82047\n",
      "val loss in 1 epoch: 4.77270\n",
      "train loss in 1 epoch in 3 batch: 5.29708\n",
      "val loss in 1 epoch: 4.77262\n",
      "train loss in 1 epoch in 4 batch: 5.06290\n",
      "val loss in 1 epoch: 4.77254\n",
      "train loss in 1 epoch in 5 batch: 5.15094\n",
      "val loss in 1 epoch: 4.77246\n",
      "train loss in 1 epoch in 6 batch: 5.38226\n",
      "val loss in 1 epoch: 4.77238\n",
      "train loss in 1 epoch in 7 batch: 4.41634\n",
      "val loss in 1 epoch: 4.77230\n",
      "train loss in 1 epoch in 8 batch: 5.63529\n",
      "val loss in 1 epoch: 4.77222\n",
      "train loss in 1 epoch in 9 batch: 4.51987\n",
      "val loss in 1 epoch: 4.77214\n",
      "train loss in 1 epoch in 10 batch: 4.84510\n",
      "val loss in 1 epoch: 4.77206\n",
      "train loss in 1 epoch in 11 batch: 5.04531\n",
      "val loss in 1 epoch: 4.77198\n",
      "train loss in 1 epoch in 12 batch: 5.25565\n",
      "val loss in 1 epoch: 4.77190\n",
      "train loss in 1 epoch in 13 batch: 4.48331\n",
      "val loss in 1 epoch: 4.77183\n",
      "train loss in 1 epoch in 14 batch: 4.75782\n",
      "val loss in 1 epoch: 4.77175\n",
      "train loss in 1 epoch in 15 batch: 5.24148\n",
      "val loss in 1 epoch: 4.77167\n",
      "train loss in 1 epoch in 16 batch: 5.11310\n",
      "val loss in 1 epoch: 4.77159\n",
      "Round 27, winrate: 0.0, max_step: 350, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/403056827.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.12788\n",
      "val loss in 1 epoch: 0.26691\n",
      "train loss in 1 epoch in 2 batch: 0.00412\n",
      "val loss in 1 epoch: 0.26690\n",
      "train loss in 1 epoch in 3 batch: 0.22729\n",
      "val loss in 1 epoch: 0.26689\n",
      "train loss in 1 epoch in 4 batch: 0.26128\n",
      "val loss in 1 epoch: 0.26689\n",
      "train loss in 1 epoch in 5 batch: 0.11989\n",
      "val loss in 1 epoch: 0.26688\n",
      "train loss in 1 epoch in 6 batch: 0.52886\n",
      "val loss in 1 epoch: 0.26687\n",
      "train loss in 1 epoch in 7 batch: 0.24084\n",
      "val loss in 1 epoch: 0.26686\n",
      "train loss in 1 epoch in 8 batch: 0.42094\n",
      "val loss in 1 epoch: 0.26686\n",
      "train loss in 1 epoch in 9 batch: 0.16527\n",
      "val loss in 1 epoch: 0.26685\n",
      "train loss in 1 epoch in 10 batch: 0.65345\n",
      "val loss in 1 epoch: 0.26684\n",
      "train loss in 1 epoch in 11 batch: 0.18446\n",
      "val loss in 1 epoch: 0.26683\n",
      "train loss in 1 epoch in 12 batch: 0.29587\n",
      "val loss in 1 epoch: 0.26683\n",
      "train loss in 1 epoch in 13 batch: 0.24521\n",
      "val loss in 1 epoch: 0.26682\n",
      "train loss in 1 epoch in 14 batch: 0.30030\n",
      "val loss in 1 epoch: 0.26681\n",
      "train loss in 1 epoch in 15 batch: 0.20143\n",
      "val loss in 1 epoch: 0.26681\n",
      "Round 28, winrate: 0.0, max_step: 319, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/115165657.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.86401\n",
      "val loss in 1 epoch: 0.69165\n",
      "train loss in 1 epoch in 2 batch: 0.49001\n",
      "val loss in 1 epoch: 0.69163\n",
      "train loss in 1 epoch in 3 batch: 1.04718\n",
      "val loss in 1 epoch: 0.69162\n",
      "train loss in 1 epoch in 4 batch: 0.63586\n",
      "val loss in 1 epoch: 0.69161\n",
      "train loss in 1 epoch in 5 batch: 0.60368\n",
      "val loss in 1 epoch: 0.69159\n",
      "Round 29, winrate: 0.0, max_step: 230, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/899990128.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.89539\n",
      "val loss in 1 epoch: -0.64049\n",
      "train loss in 1 epoch in 2 batch: -0.88615\n",
      "val loss in 1 epoch: -0.64051\n",
      "train loss in 1 epoch in 3 batch: -0.59028\n",
      "val loss in 1 epoch: -0.64052\n",
      "train loss in 1 epoch in 4 batch: -0.33507\n",
      "val loss in 1 epoch: -0.64053\n",
      "train loss in 1 epoch in 5 batch: -0.46434\n",
      "val loss in 1 epoch: -0.64055\n",
      "train loss in 1 epoch in 6 batch: -0.90686\n",
      "val loss in 1 epoch: -0.64056\n",
      "train loss in 1 epoch in 7 batch: -0.93078\n",
      "val loss in 1 epoch: -0.64057\n",
      "train loss in 1 epoch in 8 batch: -0.76664\n",
      "val loss in 1 epoch: -0.64059\n",
      "train loss in 1 epoch in 9 batch: 0.09008\n",
      "val loss in 1 epoch: -0.64060\n",
      "Round 30, winrate: 0.0, max_step: 235, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/213095930.json'}\n",
      "train loss in 1 epoch in 1 batch: -1.42191\n",
      "val loss in 1 epoch: -1.31932\n",
      "train loss in 1 epoch in 2 batch: -1.26575\n",
      "val loss in 1 epoch: -1.31933\n",
      "train loss in 1 epoch in 3 batch: -1.34162\n",
      "val loss in 1 epoch: -1.31935\n",
      "train loss in 1 epoch in 4 batch: -1.36739\n",
      "val loss in 1 epoch: -1.31937\n",
      "Round 31, winrate: 0.0, max_step: 270, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/300742822.json'}\n",
      "train loss in 1 epoch in 1 batch: 1.34356\n",
      "val loss in 1 epoch: 1.99260\n",
      "train loss in 1 epoch in 2 batch: 2.05167\n",
      "val loss in 1 epoch: 1.99256\n",
      "train loss in 1 epoch in 3 batch: 2.82438\n",
      "val loss in 1 epoch: 1.99252\n",
      "train loss in 1 epoch in 4 batch: 2.24942\n",
      "val loss in 1 epoch: 1.99248\n",
      "train loss in 1 epoch in 5 batch: 1.85559\n",
      "val loss in 1 epoch: 1.99244\n",
      "train loss in 1 epoch in 6 batch: 2.47922\n",
      "val loss in 1 epoch: 1.99240\n",
      "train loss in 1 epoch in 7 batch: 1.64207\n",
      "val loss in 1 epoch: 1.99236\n",
      "train loss in 1 epoch in 8 batch: 1.44882\n",
      "val loss in 1 epoch: 1.99233\n",
      "train loss in 1 epoch in 9 batch: 2.37846\n",
      "val loss in 1 epoch: 1.99229\n",
      "train loss in 1 epoch in 10 batch: 1.88758\n",
      "val loss in 1 epoch: 1.99225\n",
      "train loss in 1 epoch in 11 batch: 2.67459\n",
      "val loss in 1 epoch: 1.99221\n",
      "Round 32, winrate: 0.0, max_step: 115, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/586260819.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.68447\n",
      "val loss in 1 epoch: -0.64112\n",
      "train loss in 1 epoch in 2 batch: -0.84939\n",
      "val loss in 1 epoch: -0.64113\n",
      "train loss in 1 epoch in 3 batch: -0.73811\n",
      "val loss in 1 epoch: -0.64114\n",
      "train loss in 1 epoch in 4 batch: -0.38828\n",
      "val loss in 1 epoch: -0.64115\n",
      "train loss in 1 epoch in 5 batch: -0.60104\n",
      "val loss in 1 epoch: -0.64116\n",
      "train loss in 1 epoch in 6 batch: -0.73729\n",
      "val loss in 1 epoch: -0.64118\n",
      "Round 33, winrate: 0.0, max_step: 229, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/758925067.json'}\n",
      "train loss in 1 epoch in 1 batch: -1.78195\n",
      "val loss in 1 epoch: -2.38849\n",
      "train loss in 1 epoch in 2 batch: -2.87072\n",
      "val loss in 1 epoch: -2.38852\n",
      "train loss in 1 epoch in 3 batch: -2.91432\n",
      "val loss in 1 epoch: -2.38854\n",
      "train loss in 1 epoch in 4 batch: -2.30341\n",
      "val loss in 1 epoch: -2.38857\n",
      "train loss in 1 epoch in 5 batch: -2.61778\n",
      "val loss in 1 epoch: -2.38859\n",
      "train loss in 1 epoch in 6 batch: -2.43612\n",
      "val loss in 1 epoch: -2.38862\n",
      "train loss in 1 epoch in 7 batch: -2.42685\n",
      "val loss in 1 epoch: -2.38864\n",
      "Round 34, winrate: 0.0, max_step: 235, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/68105346.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.85352\n",
      "val loss in 1 epoch: -0.95988\n",
      "train loss in 1 epoch in 2 batch: -1.04205\n",
      "val loss in 1 epoch: -0.95990\n",
      "train loss in 1 epoch in 3 batch: -0.85249\n",
      "val loss in 1 epoch: -0.95992\n",
      "train loss in 1 epoch in 4 batch: -0.58137\n",
      "val loss in 1 epoch: -0.95993\n",
      "train loss in 1 epoch in 5 batch: -0.83599\n",
      "val loss in 1 epoch: -0.95995\n",
      "train loss in 1 epoch in 6 batch: -1.18335\n",
      "val loss in 1 epoch: -0.95997\n",
      "train loss in 1 epoch in 7 batch: -0.84258\n",
      "val loss in 1 epoch: -0.95998\n",
      "Round 35, winrate: 0.25, max_step: 152, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/966539241.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.60549\n",
      "val loss in 1 epoch: -0.42976\n",
      "train loss in 1 epoch in 2 batch: -0.59878\n",
      "val loss in 1 epoch: -0.42978\n",
      "train loss in 1 epoch in 3 batch: -0.01845\n",
      "val loss in 1 epoch: -0.42979\n",
      "train loss in 1 epoch in 4 batch: -0.41899\n",
      "val loss in 1 epoch: -0.42981\n",
      "train loss in 1 epoch in 5 batch: -0.67357\n",
      "val loss in 1 epoch: -0.42983\n",
      "Round 36, winrate: 0.0, max_step: 190, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/153411311.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.89967\n",
      "val loss in 1 epoch: -1.04788\n",
      "train loss in 1 epoch in 2 batch: -1.12756\n",
      "val loss in 1 epoch: -1.04788\n",
      "train loss in 1 epoch in 3 batch: -1.05856\n",
      "val loss in 1 epoch: -1.04789\n",
      "train loss in 1 epoch in 4 batch: -1.03270\n",
      "val loss in 1 epoch: -1.04790\n",
      "train loss in 1 epoch in 5 batch: -1.01893\n",
      "val loss in 1 epoch: -1.04791\n",
      "Round 37, winrate: 0.25, max_step: 359, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/13210932.json'}\n",
      "train loss in 1 epoch in 1 batch: 8.80674\n",
      "val loss in 1 epoch: 10.02794\n",
      "train loss in 1 epoch in 2 batch: 9.46382\n",
      "val loss in 1 epoch: 10.02784\n",
      "train loss in 1 epoch in 3 batch: 9.80068\n",
      "val loss in 1 epoch: 10.02775\n",
      "train loss in 1 epoch in 4 batch: 10.58336\n",
      "val loss in 1 epoch: 10.02766\n",
      "train loss in 1 epoch in 5 batch: 9.51723\n",
      "val loss in 1 epoch: 10.02756\n",
      "train loss in 1 epoch in 6 batch: 10.33646\n",
      "val loss in 1 epoch: 10.02746\n",
      "train loss in 1 epoch in 7 batch: 9.09884\n",
      "val loss in 1 epoch: 10.02737\n",
      "train loss in 1 epoch in 8 batch: 12.26648\n",
      "val loss in 1 epoch: 10.02727\n",
      "train loss in 1 epoch in 9 batch: 9.67958\n",
      "val loss in 1 epoch: 10.02717\n",
      "train loss in 1 epoch in 10 batch: 10.62599\n",
      "val loss in 1 epoch: 10.02707\n",
      "train loss in 1 epoch in 11 batch: 10.19558\n",
      "val loss in 1 epoch: 10.02697\n",
      "train loss in 1 epoch in 12 batch: 12.05185\n",
      "val loss in 1 epoch: 10.02687\n",
      "train loss in 1 epoch in 13 batch: 10.00552\n",
      "val loss in 1 epoch: 10.02677\n",
      "train loss in 1 epoch in 14 batch: 9.04687\n",
      "val loss in 1 epoch: 10.02667\n",
      "train loss in 1 epoch in 15 batch: 10.48287\n",
      "val loss in 1 epoch: 10.02657\n",
      "train loss in 1 epoch in 16 batch: 9.31850\n",
      "val loss in 1 epoch: 10.02647\n",
      "train loss in 1 epoch in 17 batch: 10.26374\n",
      "val loss in 1 epoch: 10.02638\n",
      "train loss in 1 epoch in 18 batch: 11.72542\n",
      "val loss in 1 epoch: 10.02628\n",
      "train loss in 1 epoch in 19 batch: 10.24150\n",
      "val loss in 1 epoch: 10.02619\n",
      "train loss in 1 epoch in 20 batch: 9.32817\n",
      "val loss in 1 epoch: 10.02609\n",
      "train loss in 1 epoch in 21 batch: 12.55105\n",
      "val loss in 1 epoch: 10.02600\n",
      "train loss in 1 epoch in 22 batch: 10.19539\n",
      "val loss in 1 epoch: 10.02590\n",
      "train loss in 1 epoch in 23 batch: 8.96840\n",
      "val loss in 1 epoch: 10.02581\n",
      "train loss in 1 epoch in 24 batch: 9.54059\n",
      "val loss in 1 epoch: 10.02572\n",
      "train loss in 1 epoch in 25 batch: 10.49295\n",
      "val loss in 1 epoch: 10.02562\n",
      "train loss in 1 epoch in 26 batch: 9.64026\n",
      "val loss in 1 epoch: 10.02553\n",
      "train loss in 1 epoch in 27 batch: 10.59234\n",
      "val loss in 1 epoch: 10.02544\n",
      "train loss in 1 epoch in 28 batch: 8.92256\n",
      "val loss in 1 epoch: 10.02534\n",
      "train loss in 1 epoch in 29 batch: 9.62468\n",
      "val loss in 1 epoch: 10.02525\n",
      "train loss in 1 epoch in 30 batch: 12.71443\n",
      "val loss in 1 epoch: 10.02515\n",
      "Round 38, winrate: 0.0, max_step: 155, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/873046006.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.72273\n",
      "val loss in 1 epoch: -0.71838\n",
      "train loss in 1 epoch in 2 batch: -0.71213\n",
      "val loss in 1 epoch: -0.71839\n",
      "train loss in 1 epoch in 3 batch: -0.70908\n",
      "val loss in 1 epoch: -0.71840\n",
      "train loss in 1 epoch in 4 batch: -0.10912\n",
      "val loss in 1 epoch: -0.71840\n",
      "Round 39, winrate: 0.25, max_step: 149, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/209080051.json'}\n",
      "train loss in 1 epoch in 1 batch: -1.70170\n",
      "val loss in 1 epoch: -1.58815\n",
      "train loss in 1 epoch in 2 batch: -1.79222\n",
      "val loss in 1 epoch: -1.58817\n",
      "train loss in 1 epoch in 3 batch: -1.46921\n",
      "val loss in 1 epoch: -1.58818\n",
      "train loss in 1 epoch in 4 batch: -1.74818\n",
      "val loss in 1 epoch: -1.58820\n",
      "train loss in 1 epoch in 5 batch: -1.53370\n",
      "val loss in 1 epoch: -1.58821\n",
      "Round 40, winrate: 0.0, max_step: 191, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/899990128.json'}\n",
      "train loss in 1 epoch in 1 batch: 1.54811\n",
      "val loss in 1 epoch: 1.25105\n",
      "train loss in 1 epoch in 2 batch: 1.02642\n",
      "val loss in 1 epoch: 1.25101\n",
      "train loss in 1 epoch in 3 batch: 1.59339\n",
      "val loss in 1 epoch: 1.25097\n",
      "train loss in 1 epoch in 4 batch: 1.48290\n",
      "val loss in 1 epoch: 1.25092\n",
      "train loss in 1 epoch in 5 batch: 1.47570\n",
      "val loss in 1 epoch: 1.25088\n",
      "Round 41, winrate: 0.0, max_step: 231, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/328926711.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.49313\n",
      "val loss in 1 epoch: -0.07064\n",
      "train loss in 1 epoch in 2 batch: 0.59888\n",
      "val loss in 1 epoch: -0.07066\n",
      "train loss in 1 epoch in 3 batch: -0.65576\n",
      "val loss in 1 epoch: -0.07068\n",
      "train loss in 1 epoch in 4 batch: 0.49875\n",
      "val loss in 1 epoch: -0.07070\n",
      "train loss in 1 epoch in 5 batch: -0.04905\n",
      "val loss in 1 epoch: -0.07071\n",
      "train loss in 1 epoch in 6 batch: -0.26142\n",
      "val loss in 1 epoch: -0.07073\n",
      "Round 42, winrate: 0.0, max_step: 233, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/650599866.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.09454\n",
      "val loss in 1 epoch: -0.05719\n",
      "train loss in 1 epoch in 2 batch: -0.14755\n",
      "val loss in 1 epoch: -0.05720\n",
      "train loss in 1 epoch in 3 batch: -0.04079\n",
      "val loss in 1 epoch: -0.05720\n",
      "train loss in 1 epoch in 4 batch: -0.27043\n",
      "val loss in 1 epoch: -0.05721\n",
      "train loss in 1 epoch in 5 batch: -0.11112\n",
      "val loss in 1 epoch: -0.05721\n",
      "train loss in 1 epoch in 6 batch: -0.11448\n",
      "val loss in 1 epoch: -0.05722\n",
      "train loss in 1 epoch in 7 batch: 0.20290\n",
      "val loss in 1 epoch: -0.05722\n",
      "train loss in 1 epoch in 8 batch: -0.51352\n",
      "val loss in 1 epoch: -0.05723\n",
      "train loss in 1 epoch in 9 batch: 0.23608\n",
      "val loss in 1 epoch: -0.05724\n",
      "train loss in 1 epoch in 10 batch: 0.03690\n",
      "val loss in 1 epoch: -0.05724\n",
      "train loss in 1 epoch in 11 batch: -0.16997\n",
      "val loss in 1 epoch: -0.05725\n",
      "Round 43, winrate: 0.0, max_step: 230, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/238678265.json'}\n",
      "train loss in 1 epoch in 1 batch: -2.37627\n",
      "val loss in 1 epoch: -2.11449\n",
      "train loss in 1 epoch in 2 batch: -2.20478\n",
      "val loss in 1 epoch: -2.11451\n",
      "train loss in 1 epoch in 3 batch: -2.10394\n",
      "val loss in 1 epoch: -2.11453\n",
      "train loss in 1 epoch in 4 batch: -2.66654\n",
      "val loss in 1 epoch: -2.11455\n",
      "train loss in 1 epoch in 5 batch: -2.02125\n",
      "val loss in 1 epoch: -2.11457\n",
      "train loss in 1 epoch in 6 batch: -2.22127\n",
      "val loss in 1 epoch: -2.11458\n",
      "Round 44, winrate: 0.0, max_step: 270, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/320883483.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.09213\n",
      "val loss in 1 epoch: 0.08215\n",
      "train loss in 1 epoch in 2 batch: 0.33986\n",
      "val loss in 1 epoch: 0.08214\n",
      "train loss in 1 epoch in 3 batch: 0.41962\n",
      "val loss in 1 epoch: 0.08213\n",
      "train loss in 1 epoch in 4 batch: 0.07534\n",
      "val loss in 1 epoch: 0.08212\n",
      "train loss in 1 epoch in 5 batch: 0.22198\n",
      "val loss in 1 epoch: 0.08212\n",
      "train loss in 1 epoch in 6 batch: 0.06999\n",
      "val loss in 1 epoch: 0.08211\n",
      "Round 45, winrate: 0.25, max_step: 190, example: {'ranks': [{'rank': 1, 'agentID': 0}, {'rank': 2, 'agentID': 1}], 'replayFile': 'replays/162904820.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.48490\n",
      "val loss in 1 epoch: -0.48902\n",
      "train loss in 1 epoch in 2 batch: -0.43154\n",
      "val loss in 1 epoch: -0.48902\n",
      "train loss in 1 epoch in 3 batch: -0.34161\n",
      "val loss in 1 epoch: -0.48903\n",
      "train loss in 1 epoch in 4 batch: -0.49266\n",
      "val loss in 1 epoch: -0.48903\n",
      "train loss in 1 epoch in 5 batch: -0.74264\n",
      "val loss in 1 epoch: -0.48904\n",
      "train loss in 1 epoch in 6 batch: -0.14101\n",
      "val loss in 1 epoch: -0.48904\n",
      "train loss in 1 epoch in 7 batch: -0.36564\n",
      "val loss in 1 epoch: -0.48905\n",
      "train loss in 1 epoch in 8 batch: -0.45899\n",
      "val loss in 1 epoch: -0.48906\n",
      "train loss in 1 epoch in 9 batch: -0.92522\n",
      "val loss in 1 epoch: -0.48906\n",
      "Round 46, winrate: 0.0, max_step: 359, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/145746852.json'}\n",
      "train loss in 1 epoch in 1 batch: 2.83785\n",
      "val loss in 1 epoch: 2.95963\n",
      "train loss in 1 epoch in 2 batch: 3.30153\n",
      "val loss in 1 epoch: 2.95961\n",
      "train loss in 1 epoch in 3 batch: 3.18463\n",
      "val loss in 1 epoch: 2.95958\n",
      "train loss in 1 epoch in 4 batch: 3.02302\n",
      "val loss in 1 epoch: 2.95956\n",
      "train loss in 1 epoch in 5 batch: 2.88500\n",
      "val loss in 1 epoch: 2.95953\n",
      "train loss in 1 epoch in 6 batch: 2.98035\n",
      "val loss in 1 epoch: 2.95951\n",
      "train loss in 1 epoch in 7 batch: 2.45568\n",
      "val loss in 1 epoch: 2.95948\n",
      "train loss in 1 epoch in 8 batch: 3.17753\n",
      "val loss in 1 epoch: 2.95946\n",
      "train loss in 1 epoch in 9 batch: 2.56074\n",
      "val loss in 1 epoch: 2.95943\n",
      "train loss in 1 epoch in 10 batch: 3.29663\n",
      "val loss in 1 epoch: 2.95941\n",
      "Round 47, winrate: 0.0, max_step: 358, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/62488821.json'}\n",
      "train loss in 1 epoch in 1 batch: 5.09806\n",
      "val loss in 1 epoch: 4.02287\n",
      "train loss in 1 epoch in 2 batch: 3.52490\n",
      "val loss in 1 epoch: 4.02284\n",
      "train loss in 1 epoch in 3 batch: 3.93657\n",
      "val loss in 1 epoch: 4.02281\n",
      "train loss in 1 epoch in 4 batch: 4.76288\n",
      "val loss in 1 epoch: 4.02277\n",
      "train loss in 1 epoch in 5 batch: 2.81478\n",
      "val loss in 1 epoch: 4.02274\n",
      "train loss in 1 epoch in 6 batch: 3.37965\n",
      "val loss in 1 epoch: 4.02271\n",
      "train loss in 1 epoch in 7 batch: 3.50549\n",
      "val loss in 1 epoch: 4.02268\n",
      "train loss in 1 epoch in 8 batch: 4.10754\n",
      "val loss in 1 epoch: 4.02265\n",
      "train loss in 1 epoch in 9 batch: 4.57579\n",
      "val loss in 1 epoch: 4.02262\n",
      "train loss in 1 epoch in 10 batch: 4.66638\n",
      "val loss in 1 epoch: 4.02258\n",
      "train loss in 1 epoch in 11 batch: 3.64297\n",
      "val loss in 1 epoch: 4.02255\n",
      "train loss in 1 epoch in 12 batch: 3.99014\n",
      "val loss in 1 epoch: 4.02252\n",
      "train loss in 1 epoch in 13 batch: 4.08479\n",
      "val loss in 1 epoch: 4.02248\n",
      "train loss in 1 epoch in 14 batch: 4.86946\n",
      "val loss in 1 epoch: 4.02245\n",
      "train loss in 1 epoch in 15 batch: 4.07365\n",
      "val loss in 1 epoch: 4.02241\n",
      "train loss in 1 epoch in 16 batch: 4.33261\n",
      "val loss in 1 epoch: 4.02238\n",
      "train loss in 1 epoch in 17 batch: 4.78731\n",
      "val loss in 1 epoch: 4.02235\n",
      "train loss in 1 epoch in 18 batch: 3.99805\n",
      "val loss in 1 epoch: 4.02231\n",
      "Round 48, winrate: 0.0, max_step: 358, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/141565545.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.09535\n",
      "val loss in 1 epoch: 0.10058\n",
      "train loss in 1 epoch in 2 batch: 0.02230\n",
      "val loss in 1 epoch: 0.10057\n",
      "train loss in 1 epoch in 3 batch: 0.01152\n",
      "val loss in 1 epoch: 0.10057\n",
      "train loss in 1 epoch in 4 batch: -0.14083\n",
      "val loss in 1 epoch: 0.10056\n",
      "train loss in 1 epoch in 5 batch: 0.14343\n",
      "val loss in 1 epoch: 0.10056\n",
      "train loss in 1 epoch in 6 batch: 0.35746\n",
      "val loss in 1 epoch: 0.10055\n",
      "train loss in 1 epoch in 7 batch: 0.36514\n",
      "val loss in 1 epoch: 0.10054\n",
      "train loss in 1 epoch in 8 batch: 0.47836\n",
      "val loss in 1 epoch: 0.10054\n",
      "train loss in 1 epoch in 9 batch: -0.17485\n",
      "val loss in 1 epoch: 0.10053\n",
      "train loss in 1 epoch in 10 batch: 0.35155\n",
      "val loss in 1 epoch: 0.10053\n",
      "Round 49, winrate: 0.0, max_step: 230, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/317869952.json'}\n",
      "train loss in 1 epoch in 1 batch: 2.78322\n",
      "val loss in 1 epoch: 2.64800\n",
      "train loss in 1 epoch in 2 batch: 2.18099\n",
      "val loss in 1 epoch: 2.64797\n",
      "train loss in 1 epoch in 3 batch: 2.63698\n",
      "val loss in 1 epoch: 2.64794\n",
      "train loss in 1 epoch in 4 batch: 3.44857\n",
      "val loss in 1 epoch: 2.64790\n",
      "train loss in 1 epoch in 5 batch: 3.12737\n",
      "val loss in 1 epoch: 2.64787\n",
      "train loss in 1 epoch in 6 batch: 2.83950\n",
      "val loss in 1 epoch: 2.64784\n",
      "train loss in 1 epoch in 7 batch: 2.78551\n",
      "val loss in 1 epoch: 2.64780\n",
      "train loss in 1 epoch in 8 batch: 3.02868\n",
      "val loss in 1 epoch: 2.64777\n",
      "train loss in 1 epoch in 9 batch: 2.68389\n",
      "val loss in 1 epoch: 2.64774\n",
      "train loss in 1 epoch in 10 batch: 2.92481\n",
      "val loss in 1 epoch: 2.64770\n",
      "train loss in 1 epoch in 11 batch: 3.32259\n",
      "val loss in 1 epoch: 2.64767\n",
      "train loss in 1 epoch in 12 batch: 1.18332\n",
      "val loss in 1 epoch: 2.64764\n",
      "Round 50, winrate: 0.0, max_step: 309, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/556868257.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.15400\n",
      "val loss in 1 epoch: -0.10472\n",
      "train loss in 1 epoch in 2 batch: -0.21706\n",
      "val loss in 1 epoch: -0.10472\n",
      "train loss in 1 epoch in 3 batch: -0.08079\n",
      "val loss in 1 epoch: -0.10473\n",
      "train loss in 1 epoch in 4 batch: 0.03462\n",
      "val loss in 1 epoch: -0.10474\n",
      "train loss in 1 epoch in 5 batch: 0.00595\n",
      "val loss in 1 epoch: -0.10474\n",
      "train loss in 1 epoch in 6 batch: -0.13443\n",
      "val loss in 1 epoch: -0.10475\n",
      "train loss in 1 epoch in 7 batch: -0.23218\n",
      "val loss in 1 epoch: -0.10476\n",
      "Round 51, winrate: 0.0, max_step: 155, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/68105346.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.34827\n",
      "val loss in 1 epoch: -0.39225\n",
      "train loss in 1 epoch in 2 batch: -0.46223\n",
      "val loss in 1 epoch: -0.39226\n",
      "train loss in 1 epoch in 3 batch: -0.38491\n",
      "val loss in 1 epoch: -0.39226\n",
      "train loss in 1 epoch in 4 batch: -0.50995\n",
      "val loss in 1 epoch: -0.39227\n",
      "train loss in 1 epoch in 5 batch: -0.42686\n",
      "val loss in 1 epoch: -0.39227\n",
      "train loss in 1 epoch in 6 batch: -0.44149\n",
      "val loss in 1 epoch: -0.39228\n",
      "train loss in 1 epoch in 7 batch: -0.04409\n",
      "val loss in 1 epoch: -0.39229\n",
      "Round 52, winrate: 0.0, max_step: 270, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/476274519.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.16712\n",
      "val loss in 1 epoch: -0.07985\n",
      "train loss in 1 epoch in 2 batch: 0.09979\n",
      "val loss in 1 epoch: -0.07986\n",
      "train loss in 1 epoch in 3 batch: 0.08483\n",
      "val loss in 1 epoch: -0.07987\n",
      "train loss in 1 epoch in 4 batch: 0.11136\n",
      "val loss in 1 epoch: -0.07987\n",
      "train loss in 1 epoch in 5 batch: 0.24357\n",
      "val loss in 1 epoch: -0.07988\n",
      "train loss in 1 epoch in 6 batch: -0.03531\n",
      "val loss in 1 epoch: -0.07989\n",
      "train loss in 1 epoch in 7 batch: -0.27362\n",
      "val loss in 1 epoch: -0.07990\n",
      "Round 53, winrate: 0.0, max_step: 195, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/476274519.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.13507\n",
      "val loss in 1 epoch: 0.04520\n",
      "train loss in 1 epoch in 2 batch: 0.22495\n",
      "val loss in 1 epoch: 0.04518\n",
      "train loss in 1 epoch in 3 batch: -0.35745\n",
      "val loss in 1 epoch: 0.04517\n",
      "train loss in 1 epoch in 4 batch: 0.13605\n",
      "val loss in 1 epoch: 0.04516\n",
      "train loss in 1 epoch in 5 batch: -0.07481\n",
      "val loss in 1 epoch: 0.04514\n",
      "train loss in 1 epoch in 6 batch: 0.06982\n",
      "val loss in 1 epoch: 0.04513\n",
      "train loss in 1 epoch in 7 batch: 0.14782\n",
      "val loss in 1 epoch: 0.04511\n",
      "train loss in 1 epoch in 8 batch: 0.08703\n",
      "val loss in 1 epoch: 0.04510\n",
      "Round 54, winrate: 0.0, max_step: 349, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/959344304.json'}\n",
      "train loss in 1 epoch in 1 batch: -2.82644\n",
      "val loss in 1 epoch: -2.72644\n",
      "train loss in 1 epoch in 2 batch: -2.86725\n",
      "val loss in 1 epoch: -2.72646\n",
      "train loss in 1 epoch in 3 batch: -2.45605\n",
      "val loss in 1 epoch: -2.72648\n",
      "train loss in 1 epoch in 4 batch: -2.62817\n",
      "val loss in 1 epoch: -2.72649\n",
      "train loss in 1 epoch in 5 batch: -2.67522\n",
      "val loss in 1 epoch: -2.72651\n",
      "train loss in 1 epoch in 6 batch: -3.01970\n",
      "val loss in 1 epoch: -2.72653\n",
      "train loss in 1 epoch in 7 batch: -2.97393\n",
      "val loss in 1 epoch: -2.72655\n",
      "train loss in 1 epoch in 8 batch: -3.00184\n",
      "val loss in 1 epoch: -2.72657\n",
      "Round 55, winrate: 0.0, max_step: 275, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/306883282.json'}\n",
      "train loss in 1 epoch in 1 batch: 0.32154\n",
      "val loss in 1 epoch: 0.15187\n",
      "train loss in 1 epoch in 2 batch: -0.12239\n",
      "val loss in 1 epoch: 0.15186\n",
      "train loss in 1 epoch in 3 batch: -0.00708\n",
      "val loss in 1 epoch: 0.15186\n",
      "train loss in 1 epoch in 4 batch: 0.21667\n",
      "val loss in 1 epoch: 0.15185\n",
      "train loss in 1 epoch in 5 batch: 0.37056\n",
      "val loss in 1 epoch: 0.15184\n",
      "train loss in 1 epoch in 6 batch: 0.26808\n",
      "val loss in 1 epoch: 0.15184\n",
      "train loss in 1 epoch in 7 batch: 0.18245\n",
      "val loss in 1 epoch: 0.15183\n",
      "train loss in 1 epoch in 8 batch: 0.09199\n",
      "val loss in 1 epoch: 0.15182\n",
      "Round 56, winrate: 0.0, max_step: 359, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/860159138.json'}\n",
      "train loss in 1 epoch in 1 batch: 4.89876\n",
      "val loss in 1 epoch: 4.63099\n",
      "train loss in 1 epoch in 2 batch: 5.46235\n",
      "val loss in 1 epoch: 4.63095\n",
      "train loss in 1 epoch in 3 batch: 5.18340\n",
      "val loss in 1 epoch: 4.63092\n",
      "train loss in 1 epoch in 4 batch: 4.96707\n",
      "val loss in 1 epoch: 4.63088\n",
      "train loss in 1 epoch in 5 batch: 4.49233\n",
      "val loss in 1 epoch: 4.63085\n",
      "train loss in 1 epoch in 6 batch: 4.63617\n",
      "val loss in 1 epoch: 4.63081\n",
      "train loss in 1 epoch in 7 batch: 5.27615\n",
      "val loss in 1 epoch: 4.63077\n",
      "train loss in 1 epoch in 8 batch: 4.16920\n",
      "val loss in 1 epoch: 4.63073\n",
      "train loss in 1 epoch in 9 batch: 4.48328\n",
      "val loss in 1 epoch: 4.63069\n",
      "train loss in 1 epoch in 10 batch: 5.72632\n",
      "val loss in 1 epoch: 4.63065\n",
      "train loss in 1 epoch in 11 batch: 4.39099\n",
      "val loss in 1 epoch: 4.63061\n",
      "train loss in 1 epoch in 12 batch: 5.06902\n",
      "val loss in 1 epoch: 4.63057\n",
      "train loss in 1 epoch in 13 batch: 4.71371\n",
      "val loss in 1 epoch: 4.63053\n",
      "train loss in 1 epoch in 14 batch: 5.47134\n",
      "val loss in 1 epoch: 4.63049\n",
      "train loss in 1 epoch in 15 batch: 5.03964\n",
      "val loss in 1 epoch: 4.63045\n",
      "train loss in 1 epoch in 16 batch: 5.05998\n",
      "val loss in 1 epoch: 4.63041\n",
      "train loss in 1 epoch in 17 batch: 4.04621\n",
      "val loss in 1 epoch: 4.63037\n",
      "train loss in 1 epoch in 18 batch: 4.68076\n",
      "val loss in 1 epoch: 4.63033\n",
      "train loss in 1 epoch in 19 batch: 5.12040\n",
      "val loss in 1 epoch: 4.63029\n",
      "train loss in 1 epoch in 20 batch: 4.53575\n",
      "val loss in 1 epoch: 4.63025\n",
      "train loss in 1 epoch in 21 batch: 4.27224\n",
      "val loss in 1 epoch: 4.63021\n",
      "train loss in 1 epoch in 22 batch: 4.95697\n",
      "val loss in 1 epoch: 4.63018\n",
      "Round 57, winrate: 0.0, max_step: 359, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/171197057.json'}\n",
      "train loss in 1 epoch in 1 batch: 1.70443\n",
      "val loss in 1 epoch: 2.08336\n",
      "train loss in 1 epoch in 2 batch: 1.99705\n",
      "val loss in 1 epoch: 2.08333\n",
      "train loss in 1 epoch in 3 batch: 1.97447\n",
      "val loss in 1 epoch: 2.08331\n",
      "train loss in 1 epoch in 4 batch: 2.37869\n",
      "val loss in 1 epoch: 2.08328\n",
      "train loss in 1 epoch in 5 batch: 2.14075\n",
      "val loss in 1 epoch: 2.08325\n",
      "train loss in 1 epoch in 6 batch: 2.83519\n",
      "val loss in 1 epoch: 2.08322\n",
      "train loss in 1 epoch in 7 batch: 2.17501\n",
      "val loss in 1 epoch: 2.08320\n",
      "train loss in 1 epoch in 8 batch: 2.28205\n",
      "val loss in 1 epoch: 2.08317\n",
      "train loss in 1 epoch in 9 batch: 2.28956\n",
      "val loss in 1 epoch: 2.08314\n",
      "train loss in 1 epoch in 10 batch: 1.67330\n",
      "val loss in 1 epoch: 2.08311\n",
      "Round 58, winrate: 0.0, max_step: 150, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/940981637.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.49597\n",
      "val loss in 1 epoch: -0.73772\n",
      "train loss in 1 epoch in 2 batch: -0.90607\n",
      "val loss in 1 epoch: -0.73773\n",
      "train loss in 1 epoch in 3 batch: -0.55151\n",
      "val loss in 1 epoch: -0.73774\n",
      "train loss in 1 epoch in 4 batch: -0.67200\n",
      "val loss in 1 epoch: -0.73775\n",
      "Round 59, winrate: 0.0, max_step: 271, example: {'ranks': [{'rank': 1, 'agentID': 1}, {'rank': 2, 'agentID': 0}], 'replayFile': 'replays/515205860.json'}\n",
      "train loss in 1 epoch in 1 batch: -0.72607\n",
      "val loss in 1 epoch: -0.63251\n",
      "train loss in 1 epoch in 2 batch: -0.78709\n",
      "val loss in 1 epoch: -0.63252\n",
      "train loss in 1 epoch in 3 batch: -0.67259\n",
      "val loss in 1 epoch: -0.63252\n",
      "train loss in 1 epoch in 4 batch: -0.79339\n",
      "val loss in 1 epoch: -0.63253\n",
      "train loss in 1 epoch in 5 batch: -0.47471\n",
      "val loss in 1 epoch: -0.63254\n",
      "train loss in 1 epoch in 6 batch: -0.79200\n",
      "val loss in 1 epoch: -0.63254\n",
      "train loss in 1 epoch in 7 batch: -0.80891\n",
      "val loss in 1 epoch: -0.63255\n",
      "train loss in 1 epoch in 8 batch: -0.41459\n",
      "val loss in 1 epoch: -0.63255\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-9d95671b952b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         })\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0m_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_bot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloglevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0m_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_bot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloglevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-a14bc11c0637>\u001b[0m in \u001b[0;36mrun_game\u001b[0;34m(left_bot, right_bot, seed, loglevel)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m\"--python={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m\"--seed={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \"--out={}\".format(replay_path)], stdout=subprocess.PIPE)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloglevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    949\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "B = 4\n",
    "\n",
    "model = NNWithCustomFeatures(63, 0.05, 64)\n",
    "\n",
    "while True:\n",
    "    t += 1\n",
    "    torch.save(model.state_dict(), '../submissions/simple/models/policy_iter_v{}'.format(t))\n",
    "    data = []\n",
    "    r = []\n",
    "    for i in np.arange(B):\n",
    "        seed = t * B + i\n",
    "        _f = str(seed) + \".txt\"\n",
    "        bot = build_runnable_bot_with_flags({\n",
    "            \"model_path\": \"models/policy_iter_v{}\".format(t), \n",
    "            \"use_policy\": True,\n",
    "            \"is_neural\": True,\n",
    "            \"prob_use_default_agent\": 0.1,\n",
    "            \"ohe_path\": \"models/ohe_v1\",\n",
    "            \"use_old_units_cargo_rules\": False,\n",
    "            \"log_features_path\": \"../../research/features_iter/\", \"log_path_file_name\": _f\n",
    "        })\n",
    "        if i % 2 == 0:\n",
    "            _r = run_game(bot, simple_bot, loglevel=0, seed=seed)\n",
    "        else:\n",
    "            _r = run_game(simple_bot, bot, loglevel=0, seed=seed)\n",
    "        r.append(_r)\n",
    "        data.append(dataset.get_dataset_from_file(os.path.join(\"features_iter/\", _f)))\n",
    "    trainD = dataset.concat_datasets(data)\n",
    "#     valD = sample_dataset(dataset.concat_datasets(data))\n",
    "    trainD_ohe, valD_ohe = prepare_features(trainD, trainD)\n",
    "    max_step = np.max(trainD.features[:, 21])\n",
    "    print(\"Round {}, winrate: {}, max_step: {}, example: {}\".format(t, np.mean(count_series(r)), max_step, r[0][0]['results']))\n",
    "    learn(trainD_ohe, valD_ohe, model, policy_loss, lr=1e-5 / np.log(t + 1), batch_size=64, epochs=1, freq=1, l2=1e-3, use_tb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.forward(torch.Tensor(trainD_ohe.features[0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
